# README

HCI Lab1-1：Automatic Speech Recognition

# 1. Enivronment

- **Pycharm** Community Edition 2022.1.3
- **Windows** 10 Professional

Please `download` these packages to configure your python enviroment before you use it. And make sure that the internet is connected.

```
pywhatkit
pypiwin32
PyQt5
gtts
playsound
SpeechRecognition
```

# 2. Usage

- Run the `main.py` file.

- Click the **Start** button to wake up Salexa.

- After starting the assistant, you can say different commands to use different functions.

  - **Play music** → Say ”*Play music*”

  - **Open a text file** →Say “*Open notepad*”

  - **Search on the internet** → Say “*Search for XXX*” or “*Tell me Something about XXX*” or just say “*XXX*”

  - **Exit the page** → Say “*Exit*” or *“Stop”*

- Certainly, you can also exit the page by click the **Exit** button.

- In addition, you can pull the **scroll bar** to see what you just said.

# 3. Structure

```
│  main.py
│  music.mp3  
├─icon
│   listen.gif
│   loading.gif
│   normal.gif
│   play.gif   
└─sounds
    alert.mp3
    output.mp3
```

# 4. References

- **[How to CODE Siri or Alexa](https://www.youtube.com/watch?v=bwTtvuyyhEQ)** by SalteeKiller
- **[the Tutorial of PyQt5](https://doc.itprojects.cn/0001.zhishi/python.0008.pyqt5rumen/index.html#/README)**  by itprojects.cn
- [Gif Icons](https://cdn.dribbble.com/users/14038/screenshots/6371784/800-600.gif)
